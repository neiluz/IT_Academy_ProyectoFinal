{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c2fb79",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #1DA1F2; padding: 20px;\"><b><h1> Descifrando el lenguaje emocional en Twitter: Un an√°lisis predictivo basado en aprendizaje autom√°tico. </h1></b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98964068",
   "metadata": {},
   "source": [
    "**Autor**: Neivys Luz Gonz√°lez G√≥mez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688086f",
   "metadata": {},
   "source": [
    "La identificaci√≥n de emociones es una tarea fundamental en el campo del procesamiento de lenguaje natural, que se enfoca en clasificar textos seg√∫n su tono emocional. A pesar de que el objetivo es identificar una amplia variedad de emociones humanas, la mayor√≠a de los conjuntos de datos disponibles se limitan a las polaridades positiva, negativa y, en ocasiones, neutral.\n",
    "\n",
    "Detectar emociones a partir de textos es un reto complejo en el procesamiento del lenguaje natural, ya que se trata de un problema de clasificaci√≥n multiclase y, en muchas ocasiones, no hay suficientes datos etiquetados disponibles. Sin embargo, este conjunto de datos etiquetado proporciona la oportunidad de aplicar diversas t√©cnicas de an√°lisis exploratorio y modelado para entender mejor la din√°mica emocional en las redes sociales y mejorar la capacidad de detecci√≥n en tiempo real.\n",
    "\n",
    "El conjunto de datos de emociones se obtiene a partir de mensajes en ingl√©s de Twitter y contiene seis emociones b√°sicas: neutralidad, preocupaci√≥n, felicidad, tristeza, amor, sorpresa, diversi√≥n, alivio, odio, vac√≠o, entusiasmo y aburrimiento. Este conjunto de datos ofrece una variedad m√°s amplia de emociones humanas, lo que permite el entrenamiento y la evaluaci√≥n de modelos de an√°lisis de sentimientos con mayor precisi√≥n y exhaustividad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338c1f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alert-info\"><b><h3>Objetivo General</h3></b>\n",
    "    \n",
    "**Desarrollar un modelo que permita detectar emociones en los tweets y analizar patrones en el lenguaje utilizado en Twitter para ayudar en la detecci√≥n temprana de trastornos emocionales como la depresi√≥n, la ansiedad, entre otros.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a51b43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c744d",
   "metadata": {},
   "source": [
    "# Notebook N¬∞ 8: Comprobacci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bce73",
   "metadata": {},
   "source": [
    "En este notebook, se presenta la predicci√≥n de la variable objetivo utilizando el mejor modelo obtenido previamente mediante un proceso de Pipeline. En primer lugar, realizaremos el procesamiento previo al conjunto de datos sin incluir la variable objetivo. Posteriormente, aplicaremos el modelo con los par√°metros √≥ptimos y llevaremos a cabo la predicci√≥n de la variable objetivo, en este caso, la prediccion de la emociones: negative: 0, neutral: 1, y positive: 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad62d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebecf44",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#import NLTK\n",
    "import nltk\n",
    "nltk.download('punkt') #Punkt es una biblioteca que se utiliza para tokenizar frases en lenguaje natural\n",
    "nltk.download('stopwords') # library \"stopwords\"\n",
    "nltk.download('wordnet') # \n",
    "nltk.download('omw-1.4') #\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#import librerias de pre-procesamiento y normalizacion\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e886e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic modules from sklearn\n",
    "from scipy import stats ## to check normality and variance of columns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler, LabelBinarizer, OrdinalEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "## Importn Classification models\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "## Sabe pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af241c3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023cc194",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><h2> Cargar Dataset.</h2></b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f07eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data= pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92b8fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \n",
       "0      @tiffanylue i know  i was listenin to bad habi...  \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                    Funeral ceremony...gloomy friday...  \n",
       "3                   wants to hang out with friends SOON!  \n",
       "4      @dannycastillo We want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                   @JohnLloydTaylor  \n",
       "39996                     Happy Mothers Day  All my love  \n",
       "39997  Happy Mother's Day to all the mommies out ther...  \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b6fb8",
   "metadata": {},
   "source": [
    "## 1. Preparaci√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537e7eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   author     40000 non-null  object\n",
      " 3   content    40000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "emotion_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563909d2",
   "metadata": {},
   "source": [
    "## 2. Pre-procesamiento del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb16633",
   "metadata": {},
   "source": [
    "### 2.1 Limpieza del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e820fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_tweets(df, column_name):\n",
    "    # Print tweets with less than 5 characters\n",
    "    print(f\"Tweets with less than 5 characters in column '{column_name}':\")\n",
    "    short_tweets = df[df[column_name].str.len() < 5][column_name]\n",
    "    print(short_tweets)\n",
    "    \n",
    "    # Drop rows with less than 5 characters in the tweet\n",
    "    df.drop(df[df[column_name].str.len() < 5].index, inplace=True)\n",
    "    \n",
    "    print(f\"Total number of rows removed: {len(short_tweets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b5c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention_only_tweets(df, column_name):\n",
    "    # Print tweets with only mentions (and + 0, or 1 characters)\n",
    "    print(f\"Tweets with only mentions in column '{column_name}':\")\n",
    "    mention_only_tweets = df[df[column_name].str.replace(\"@[^\\s]+\", \"\").str.len() < 2][column_name]\n",
    "    print(mention_only_tweets)\n",
    "    \n",
    "    # Drop the tweets that contain only mentions\n",
    "    df.drop(df[df[column_name].str.replace(\"@[^\\s]+\", \"\").str.len()<2].index, inplace=True)\n",
    "    \n",
    "    print(f\"Total number of rows removed: {len(mention_only_tweets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8925a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_dataframe_indexes(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"DataFrame indexes reset successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c110bbc",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def preproces_tweet(tweet):\n",
    "    # Eliminar menciones (@nombredeusuario) y URLs\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+|https?://[A-Za-z0-9./]+', '', tweet)\n",
    "    \n",
    "    # Convertir el texto a min√∫sculas\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Eliminar signos de puntuaci√≥n\n",
    "    tweet = re.sub('[%s]' % re.escape(string.punctuation), '', tweet)\n",
    "    \n",
    "    # Eliminar n√∫meros\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    \n",
    "    # Eliminar palabras comunes (stopwords)\n",
    "    stop_words = stopwords.words('english') + ['u', 'im', 'c', 'n']\n",
    "    words = tweet.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lematizaci√≥n (reducir las palabras a su ra√≠z)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    tweet = ' '.join(words)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb712166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_space_records(df, column_name):\n",
    "    if '' in df[column_name].values:\n",
    "        print(df[column_name].value_counts()[''])\n",
    "    else:\n",
    "        print(f\"No hay valores vac√≠os en '{column_name}'.\")\n",
    "        \n",
    "    # Eliminar los registros con espacios vac√≠os\n",
    "    df.drop(df[df[column_name] == ''].index, inplace=True)\n",
    "    \n",
    "    # Resetear los √≠ndices\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"Registros con espacios vac√≠os eliminados y los √≠ndices reseteados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d74787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(df, column_name):\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    print(f\"La columna '{column_name}' ha sido convertida a tipo 'string'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91653f",
   "metadata": {},
   "source": [
    "### 2.2  Polaridad con VADER (Valence Aware Dictionary and sEntiment Reasoner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48662f44",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def add_vader_sentiment_column(df, column_name):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_data_vader = df[column_name].apply(lambda tweet: analyzer.polarity_scores(tweet))\n",
    "    sentiment_data_vader = pd.json_normalize(sentiment_data_vader)\n",
    "    sentiment_data_vader[\"polarity_vader\"] = sentiment_data_vader[\"compound\"].apply(lambda c: \"positive\" if c > 0.3 else \"negative\" if c < -0.3 else \"neutral\")\n",
    "    df = pd.concat([df, sentiment_data_vader], axis=1)\n",
    "    print(\"La columna de an√°lisis de polaridad de Vader ha sido agregada al DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0a749",
   "metadata": {},
   "source": [
    "### 2.3 Label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c49b508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_polarity_vader_column(df):\n",
    "    le = LabelEncoder()\n",
    "    df['polarity_vader'] = le.fit_transform(df['polarity_vader'])\n",
    "    print(\"La columna de polaridad de Vader ha sido codificada con √©xito.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baa0e2",
   "metadata": {},
   "source": [
    "### 2.4 Selecci√≥n de columnas (Feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632963a9",
   "metadata": {},
   "source": [
    "Se eliminaran columnas innecesarias para el estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ad5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_and_reset(df):\n",
    "    # Eliminar columnas no utilizadas\n",
    "    df.drop(['tweet_id', 'author', 'sentiment', 'neg', 'neu', 'pos', 'compound'], axis=1, inplace=True)\n",
    "    print(\"Las columnas no utilizadas han sido eliminadas con √©xito.\")\n",
    "    \n",
    "    # Resetear los √≠ndices\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Los √≠ndices han sido restablecidos con √©xito.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da912be0",
   "metadata": {},
   "source": [
    "### 2.5 Conjunto de datos pre-procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "558039f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets with less than 5 characters in column 'content':\n",
      "340      0\n",
      "15028    0\n",
      "29869    0\n",
      "39415    0\n",
      "Name: content, dtype: object\n",
      "Total number of rows removed: 4\n",
      "Tweets with only mentions in column 'content':\n",
      "659      @Joshuah_Pearson\n",
      "664             @emlevins\n",
      "3181          @Clumsyflic\n",
      "4865        @philleasfogg\n",
      "4933           @WillKnott\n",
      "               ...       \n",
      "38438        @MariahCarey\n",
      "38650      @Britt_Uh_Knee\n",
      "39206        @hmigroupllc\n",
      "39518        @Remy_Foster\n",
      "39995    @JohnLloydTaylor\n",
      "Name: content, Length: 77, dtype: object\n",
      "Total number of rows removed: 77\n",
      "DataFrame indexes reset successfully!\n",
      "127\n",
      "Registros con espacios vac√≠os eliminados y los √≠ndices reseteados.\n",
      "La columna 'content' ha sido convertida a tipo 'string'.\n"
     ]
    }
   ],
   "source": [
    "#Remove short tweets\n",
    "remove_short_tweets(emotion_data, \"content\")\n",
    "\n",
    "#remove mention only tweets\n",
    "remove_mention_only_tweets(emotion_data, \"content\")\n",
    "\n",
    "#reset dataframe indexes\n",
    "reset_dataframe_indexes(emotion_data)\n",
    "\n",
    "#pre-procesar los tweets\n",
    "emotion_data['content'] = emotion_data['content'].apply(preproces_tweet)\n",
    "\n",
    "#remove empty space records\n",
    "remove_empty_space_records(emotion_data, \"content\")\n",
    "\n",
    "#convert to string\n",
    "convert_to_string(emotion_data, \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a66bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna de an√°lisis de polaridad de Vader ha sido agregada al DataFrame.\n",
      "La columna de polaridad de Vader ha sido codificada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "#add vader sentiment column\n",
    "emotion_data = add_vader_sentiment_column(emotion_data, \"content\")\n",
    "\n",
    "#encode polarity vader column\n",
    "emotion_data = encode_polarity_vader_column(emotion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc6dd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>polarity_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>know listenin bad habit earlier started freaki...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin bed headache ughhhhwaitin call</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>want hang friend soon</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content    neg    neu    pos  \\\n",
       "0  know listenin bad habit earlier started freaki...  0.333  0.667  0.000   \n",
       "1               layin bed headache ughhhhwaitin call  0.000  1.000  0.000   \n",
       "2                      funeral ceremonygloomy friday  0.556  0.444  0.000   \n",
       "3                              want hang friend soon  0.000  0.308  0.692   \n",
       "4              want trade someone houston ticket one  0.000  0.794  0.206   \n",
       "\n",
       "   compound  polarity_vader  \n",
       "0   -0.5423               0  \n",
       "1    0.0000               1  \n",
       "2   -0.3612               0  \n",
       "3    0.5423               2  \n",
       "4    0.0772               1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1477c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las columnas no utilizadas han sido eliminadas con √©xito.\n",
      "Los √≠ndices han sido restablecidos con √©xito.\n"
     ]
    }
   ],
   "source": [
    "#drop and reset\n",
    "emotion_data = drop_and_reset(emotion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea2fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39792 entries, 0 to 39791\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         39792 non-null  object\n",
      " 1   polarity_vader  39792 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 466.4+ KB\n"
     ]
    }
   ],
   "source": [
    "emotion_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a985404",
   "metadata": {},
   "source": [
    "## 3. Crear  la Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e23bdf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer(lowercase=False)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('model',\n",
       "                 SGDClassifier(class_weight='balanced', penalty='l1',\n",
       "                               random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with best parameters\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('vector', CountVectorizer(lowercase=False)), \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('model', SGDClassifier(random_state=42, alpha= 0.0001, class_weight='balanced', max_iter=1000, \n",
    "                                penalty='l1'))\n",
    "    ]\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c18ba",
   "metadata": {},
   "source": [
    "## 4. Entrenar  la Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91317a0d",
   "metadata": {},
   "source": [
    "Primero se separa los datos de entrenamiento en caracter√≠stica y objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc04af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features df\n",
    "X_train = emotion_data['content']\n",
    "\n",
    "## Crete target df\n",
    "y_train = emotion_data['polarity_vader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa94a84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        know listenin bad habit earlier started freaki...\n",
       "1                     layin bed headache ughhhhwaitin call\n",
       "2                            funeral ceremonygloomy friday\n",
       "3                                    want hang friend soon\n",
       "4                    want trade someone houston ticket one\n",
       "                               ...                        \n",
       "39787                          succesfully following tayla\n",
       "39788                                happy mother day love\n",
       "39789    happy mother day mommy woman man long youre mo...\n",
       "39790    wassup beautiful follow peep new hit single ww...\n",
       "39791    bullet train tokyo gf visiting japan since thu...\n",
       "Name: content, Length: 39792, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display X\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2b617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        2\n",
       "4        1\n",
       "        ..\n",
       "39787    1\n",
       "39788    2\n",
       "39789    2\n",
       "39790    2\n",
       "39791    1\n",
       "Name: polarity_vader, Length: 39792, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display y_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46112899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer(lowercase=False)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('model',\n",
       "                 SGDClassifier(class_weight='balanced', penalty='l1',\n",
       "                               random_state=42))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the pipline with training data\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81104da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4d928",
   "metadata": {},
   "source": [
    "## Predict the target with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c39a8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "pipeline_loaded = joblib.load('best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b56d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading test data\n",
    "X_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8ca38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets with less than 5 characters in column 'tweet':\n",
      "189     love\n",
      "259     love\n",
      "365     love\n",
      "369     love\n",
      "445     love\n",
      "500     love\n",
      "525     love\n",
      "586     love\n",
      "626     hate\n",
      "664     love\n",
      "721     love\n",
      "807     love\n",
      "847     love\n",
      "1135    love\n",
      "1209    love\n",
      "1211    love\n",
      "1270    love\n",
      "1284    love\n",
      "1437    love\n",
      "1440    love\n",
      "1452    love\n",
      "1602      ‚òùüèª\n",
      "1610    love\n",
      "1677    love\n",
      "1739    love\n",
      "1743    love\n",
      "1786    love\n",
      "1800    love\n",
      "1832    love\n",
      "1872    love\n",
      "1880    love\n",
      "1955    love\n",
      "1974     yes\n",
      "2019    love\n",
      "2176    yeah\n",
      "2261    love\n",
      "2287    love\n",
      "2330    love\n",
      "2381    love\n",
      "2412    love\n",
      "2416    love\n",
      "2475    love\n",
      "2491    hate\n",
      "2503    love\n",
      "2516    hate\n",
      "2584    love\n",
      "Name: tweet, dtype: object\n",
      "Total number of rows removed: 46\n",
      "Tweets with only mentions in column 'tweet':\n",
      "Series([], Name: tweet, dtype: object)\n",
      "Total number of rows removed: 0\n",
      "DataFrame indexes reset successfully!\n",
      "No hay valores vac√≠os en 'tweet'.\n",
      "Registros con espacios vac√≠os eliminados y los √≠ndices reseteados.\n",
      "La columna 'tweet' ha sido convertida a tipo 'string'.\n",
      "DataFrame indexes reset successfully!\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing the tweets\n",
    "\n",
    "#Remove short tweets\n",
    "remove_short_tweets(X_test, \"tweet\")\n",
    "\n",
    "#remove mention only tweets\n",
    "remove_mention_only_tweets(X_test, \"tweet\")\n",
    "\n",
    "#reset dataframe indexes\n",
    "reset_dataframe_indexes(X_test)\n",
    "\n",
    "#pre-procesar los tweets\n",
    "X_test['tweet'] = X_test['tweet'].apply(preproces_tweet)\n",
    "\n",
    "#remove empty space records\n",
    "remove_empty_space_records(X_test, \"tweet\")\n",
    "\n",
    "#convert to string\n",
    "convert_to_string(X_test, \"tweet\")\n",
    "\n",
    "#reset dataframe indexes\n",
    "reset_dataframe_indexes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb1267b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please offer cc atv color blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always love always ill go always love always l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>careful date alot people aint looking love loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tik tok ceo experience available child singapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>ready love trust always business help eachothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>it‚Äôs ramadan need quiet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>haaaaappy birthday love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>word hate subjective pending lens youre lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>wholly agree today lodge ‚Äòmentorship scheme‚Äô i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "0                        please offer cc atv color blue\n",
       "1     always love always ill go always love always l...\n",
       "2     careful date alot people aint looking love loo...\n",
       "3                                               love xx\n",
       "4     tik tok ceo experience available child singapo...\n",
       "...                                                 ...\n",
       "2567  ready love trust always business help eachothe...\n",
       "2568                            it‚Äôs ramadan need quiet\n",
       "2569                            haaaaappy birthday love\n",
       "2570  word hate subjective pending lens youre lookin...\n",
       "2571  wholly agree today lodge ‚Äòmentorship scheme‚Äô i...\n",
       "\n",
       "[2572 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display X\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d584add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['emotion label'] = pipeline_loaded.predict(X_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1551734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2572 entries, 0 to 2571\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweet          2572 non-null   object\n",
      " 1   emotion label  2572 non-null   int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 30.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb9bc730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please offer cc atv color blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always love always ill go always love always l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>careful date alot people aint looking love loo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love xx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tik tok ceo experience available child singapo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beyondfast love nvidia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>james kjv blessed man endureth temptation trie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thx drop love arb ‚ù§Ô∏è</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>love sing top lungsand range master bathroom p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sudden stream tonight fun thanks pummel party ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aesthetic demolished empty lot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>right it‚Äôs lot comprehend especially many new ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>happy birthday love big enjoy day blast</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>would hang beautiful cloud sunrise canvas prin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>girl bringing daughter tweet babygirl she‚Äôs be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love spiderman love suit don‚Äôt like one also l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yeiii bien merecido ü•≥üíú congrats jimin love ü•∞üëèüèª...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>‚ú®‚ú®everyone know love youüå∏üå∏üå∏üå∏üå∏üå∏ ‰∏äÊµ∑ËµÑÊ∫ê ‰∏äÊµ∑‰∏ùË∂≥</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i‚Äôm ready get decked marchmadness i‚Äôd love sna...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>man love missy elliott much</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  emotion label\n",
       "0                      please offer cc atv color blue              2\n",
       "1   always love always ill go always love always l...              2\n",
       "2   careful date alot people aint looking love loo...              2\n",
       "3                                             love xx              2\n",
       "4   tik tok ceo experience available child singapo...              1\n",
       "5                              beyondfast love nvidia              2\n",
       "6   james kjv blessed man endureth temptation trie...              2\n",
       "7                                thx drop love arb ‚ù§Ô∏è              2\n",
       "8   love sing top lungsand range master bathroom p...              2\n",
       "9   sudden stream tonight fun thanks pummel party ...              2\n",
       "10                     aesthetic demolished empty lot              1\n",
       "11  right it‚Äôs lot comprehend especially many new ...              2\n",
       "12            happy birthday love big enjoy day blast              2\n",
       "13  would hang beautiful cloud sunrise canvas prin...              2\n",
       "14  girl bringing daughter tweet babygirl she‚Äôs be...              2\n",
       "15  love spiderman love suit don‚Äôt like one also l...              2\n",
       "16  yeiii bien merecido ü•≥üíú congrats jimin love ü•∞üëèüèª...              2\n",
       "17           ‚ú®‚ú®everyone know love youüå∏üå∏üå∏üå∏üå∏üå∏ ‰∏äÊµ∑ËµÑÊ∫ê ‰∏äÊµ∑‰∏ùË∂≥              2\n",
       "18  i‚Äôm ready get decked marchmadness i‚Äôd love sna...              2\n",
       "19                        man love missy elliott much              2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c015e591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>nani bestie fr love itü´∂ü´∂ü´∂</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>love love said yo man defending rape grooming ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>ghanaians always criticise black star love alw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>he‚Äôs playing good lmao</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>sad god happiness unconditional love üò¢</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>celebrate nationalpuppyday üê∂ lot puppy love sn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>ü§£ alcahol force happiness moes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>back root daenerys stormborn egyptianish fashi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>rt struggling ignite love reading student üî• ch...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>literal sacrifice life since old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>like father like son love esraüòçüòçüòç</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>love mate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>everyone love talking bipolar egirls shit one ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>üîä nowplaying bbcradios futuresounds claraamfo ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>post depressed gender give break female litera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>ready love trust always business help eachothe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>it‚Äôs ramadan need quiet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>haaaaappy birthday love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>word hate subjective pending lens youre lookin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>wholly agree today lodge ‚Äòmentorship scheme‚Äô i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  emotion label\n",
       "2552                          nani bestie fr love itü´∂ü´∂ü´∂              2\n",
       "2553  love love said yo man defending rape grooming ...              2\n",
       "2554  ghanaians always criticise black star love alw...              2\n",
       "2555                             he‚Äôs playing good lmao              2\n",
       "2556             sad god happiness unconditional love üò¢              2\n",
       "2557  celebrate nationalpuppyday üê∂ lot puppy love sn...              2\n",
       "2558                     ü§£ alcahol force happiness moes              1\n",
       "2559  back root daenerys stormborn egyptianish fashi...              1\n",
       "2560  rt struggling ignite love reading student üî• ch...              2\n",
       "2561                   literal sacrifice life since old              1\n",
       "2562                  like father like son love esraüòçüòçüòç              2\n",
       "2563                                          love mate              2\n",
       "2564  everyone love talking bipolar egirls shit one ...              2\n",
       "2565  üîä nowplaying bbcradios futuresounds claraamfo ...              2\n",
       "2566  post depressed gender give break female litera...              0\n",
       "2567  ready love trust always business help eachothe...              2\n",
       "2568                            it‚Äôs ramadan need quiet              1\n",
       "2569                            haaaaappy birthday love              2\n",
       "2570  word hate subjective pending lens youre lookin...              0\n",
       "2571  wholly agree today lodge ‚Äòmentorship scheme‚Äô i...              2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7c97f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1836\n",
       "0     453\n",
       "1     283\n",
       "Name: emotion label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['emotion label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11a46292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>literally changed ecosystem fun‚Ä¶‚Ä¶i hate ppl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>‚Äúi piece shit man cheated wife instead helping...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ive watching entire life hate air breathes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>god made depressed broke airpods see would happen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>harmstrong don‚Äôt hate couple share everything üòÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>everything make anxious hate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>bill hate drafting offense unless name josh al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>mom like yolanda hadid lmao hate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>post depressed gender give break female litera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>word hate subjective pending lens youre lookin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  emotion label\n",
       "23          literally changed ecosystem fun‚Ä¶‚Ä¶i hate ppl              0\n",
       "25    ‚Äúi piece shit man cheated wife instead helping...              0\n",
       "26           ive watching entire life hate air breathes              0\n",
       "27    god made depressed broke airpods see would happen              0\n",
       "34      harmstrong don‚Äôt hate couple share everything üòÇ              0\n",
       "...                                                 ...            ...\n",
       "2539                       everything make anxious hate              0\n",
       "2541  bill hate drafting offense unless name josh al...              0\n",
       "2545                   mom like yolanda hadid lmao hate              0\n",
       "2566  post depressed gender give break female litera...              0\n",
       "2570  word hate subjective pending lens youre lookin...              0\n",
       "\n",
       "[453 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['emotion label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e374fa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tik tok ceo experience available child singapo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aesthetic demolished empty lot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>empty space neta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>dont worry future okay let live present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>reader little folio reason anger long appear w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>‚Äútake responsibility happiness never put peopl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>ü§£ alcahol force happiness moes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>back root daenerys stormborn egyptianish fashi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>literal sacrifice life since old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>it‚Äôs ramadan need quiet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  emotion label\n",
       "4     tik tok ceo experience available child singapo...              1\n",
       "10                       aesthetic demolished empty lot              1\n",
       "32                                     empty space neta              1\n",
       "38              dont worry future okay let live present              1\n",
       "45    reader little folio reason anger long appear w...              1\n",
       "...                                                 ...            ...\n",
       "2551  ‚Äútake responsibility happiness never put peopl...              1\n",
       "2558                     ü§£ alcahol force happiness moes              1\n",
       "2559  back root daenerys stormborn egyptianish fashi...              1\n",
       "2561                   literal sacrifice life since old              1\n",
       "2568                            it‚Äôs ramadan need quiet              1\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['emotion label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "520def81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please offer cc atv color blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always love always ill go always love always l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>careful date alot people aint looking love loo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love xx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beyondfast love nvidia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>everyone love talking bipolar egirls shit one ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>üîä nowplaying bbcradios futuresounds claraamfo ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>ready love trust always business help eachothe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>haaaaappy birthday love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>wholly agree today lodge ‚Äòmentorship scheme‚Äô i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1836 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  emotion label\n",
       "0                        please offer cc atv color blue              2\n",
       "1     always love always ill go always love always l...              2\n",
       "2     careful date alot people aint looking love loo...              2\n",
       "3                                               love xx              2\n",
       "5                                beyondfast love nvidia              2\n",
       "...                                                 ...            ...\n",
       "2564  everyone love talking bipolar egirls shit one ...              2\n",
       "2565  üîä nowplaying bbcradios futuresounds claraamfo ...              2\n",
       "2567  ready love trust always business help eachothe...              2\n",
       "2569                            haaaaappy birthday love              2\n",
       "2571  wholly agree today lodge ‚Äòmentorship scheme‚Äô i...              2\n",
       "\n",
       "[1836 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['emotion label'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9182eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
